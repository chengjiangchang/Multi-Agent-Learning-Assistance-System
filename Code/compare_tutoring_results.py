#!/usr/bin/env python3
"""
ÂØπÊØîÊñ∞Êóß Tutoring Only Ê®°ÂºèÁöÑÂÆûÈ™åÁªìÊûú

ÂØπÊØîÊåáÊ†áÔºö
- Task1 (Ëá™ÊàëÈ¢ÑÊµã) ÂáÜÁ°ÆÁéá„ÄÅF1„ÄÅ‰∫§ÂèâÁÜµ
- Task4 (Á≠îÊ°àÈÄâÊã©) ÂáÜÁ°ÆÁéá„ÄÅF1
- Task2 (Áü•ËØÜÁÇπËØÜÂà´) ÂáÜÁ°ÆÁéá
"""

import os
import re


def extract_metrics_from_report(report_path):
    """‰ªéÊä•ÂëäÊñá‰ª∂‰∏≠ÊèêÂèñÊåáÊ†á"""
    if not os.path.exists(report_path):
        print(f"‚ùå Êä•ÂëäÊñá‰ª∂‰∏çÂ≠òÂú®: {report_path}")
        return None
    
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Êü•Êâæ TUTORING ONLY ÈÉ®ÂàÜ
    tutoring_section = re.search(
        r'üü° TUTORING ONLY.*?(?=üîµ|üü¢|üìä|$)',
        content,
        re.DOTALL
    )
    
    if not tutoring_section:
        print("‚ùå Êú™ÊâæÂà∞ TUTORING ONLY ÈÉ®ÂàÜ")
        return None
    
    section_text = tutoring_section.group(0)
    
    # ÊèêÂèñÊåáÊ†á
    metrics = {}
    
    # Task1 ÊåáÊ†á
    task1_acc = re.search(r'Task1.*?ÂáÜÁ°ÆÁéá.*?(\d+\.\d+)%', section_text, re.DOTALL)
    task1_f1 = re.search(r'Task1.*?F1-Score.*?(\d+\.\d+)', section_text, re.DOTALL)
    task1_ce = re.search(r'Task1.*?‰∫§ÂèâÁÜµ.*?(\d+\.\d+)', section_text, re.DOTALL)
    
    # Task4 ÊåáÊ†á
    task4_acc = re.search(r'Task4.*?ÂáÜÁ°ÆÁéá.*?(\d+\.\d+)%', section_text, re.DOTALL)
    task4_f1 = re.search(r'Task4.*?F1-Score.*?(\d+\.\d+)', section_text, re.DOTALL)
    
    # Task2 ÊåáÊ†á
    task2_acc = re.search(r'Task2.*?ÂáÜÁ°ÆÁéá.*?(\d+\.\d+)%', section_text, re.DOTALL)
    
    if task1_acc:
        metrics['task1_acc'] = float(task1_acc.group(1))
    if task1_f1:
        metrics['task1_f1'] = float(task1_f1.group(1))
    if task1_ce:
        metrics['task1_ce'] = float(task1_ce.group(1))
    if task4_acc:
        metrics['task4_acc'] = float(task4_acc.group(1))
    if task4_f1:
        metrics['task4_f1'] = float(task4_f1.group(1))
    if task2_acc:
        metrics['task2_acc'] = float(task2_acc.group(1))
    
    return metrics


def compare_results(old_metrics, new_metrics):
    """ÂØπÊØîÊñ∞ÊóßÁªìÊûú"""
    print("\n" + "="*80)
    print("üìä Tutoring Only Ê®°Âºè - ÊîπËøõÊïàÊûúÂØπÊØî".center(80))
    print("="*80)
    
    if not old_metrics or not new_metrics:
        print("‚ùå Êó†Ê≥ïÂØπÊØîÔºöÁº∫Â∞ëÂøÖË¶ÅÁöÑÊåáÊ†áÊï∞ÊçÆ")
        return
    
    print("\nüìà Task1 (Ëá™ÊàëÈ¢ÑÊµã) - Â≠¶ÁîüËÉΩÂê¶Ê≠£Á°ÆÈ¢ÑÊµãËá™Â∑±ÁöÑË°®Áé∞")
    print("-"*80)
    compare_metric("ÂáÜÁ°ÆÁéá (ACC)", old_metrics.get('task1_acc'), new_metrics.get('task1_acc'), '%', higher_is_better=True)
    compare_metric("F1-Score", old_metrics.get('task1_f1'), new_metrics.get('task1_f1'), '', higher_is_better=True)
    compare_metric("‰∫§ÂèâÁÜµ (CE)", old_metrics.get('task1_ce'), new_metrics.get('task1_ce'), '', higher_is_better=False)
    
    print("\nüìù Task4 (Á≠îÊ°àÈÄâÊã©) - Â≠¶ÁîüÁöÑÂÆûÈôÖÂÅöÈ¢òË°®Áé∞")
    print("-"*80)
    compare_metric("ÂáÜÁ°ÆÁéá (ACC)", old_metrics.get('task4_acc'), new_metrics.get('task4_acc'), '%', higher_is_better=True)
    compare_metric("F1-Score", old_metrics.get('task4_f1'), new_metrics.get('task4_f1'), '', higher_is_better=True)
    
    print("\nüéØ Task2 (Áü•ËØÜÁÇπËØÜÂà´)")
    print("-"*80)
    compare_metric("ÂáÜÁ°ÆÁéá (ACC)", old_metrics.get('task2_acc'), new_metrics.get('task2_acc'), '%', higher_is_better=True)
    
    print("\n" + "="*80)
    print("üí° ÊîπËøõÊÄªÁªì".center(80))
    print("="*80)
    
    # ËÆ°ÁÆóÊï¥‰ΩìÊîπËøõ
    improvements = 0
    declines = 0
    
    for key in ['task1_acc', 'task1_f1', 'task4_acc', 'task4_f1', 'task2_acc']:
        if key in old_metrics and key in new_metrics:
            if new_metrics[key] > old_metrics[key]:
                improvements += 1
            elif new_metrics[key] < old_metrics[key]:
                declines += 1
    
    # task1_ceË∂ä‰ΩéË∂äÂ•Ω
    if 'task1_ce' in old_metrics and 'task1_ce' in new_metrics:
        if new_metrics['task1_ce'] < old_metrics['task1_ce']:
            improvements += 1
        else:
            declines += 1
    
    print(f"\n   ‚úÖ ÊîπËøõÊåáÊ†á: {improvements} ‰∏™")
    print(f"   ‚ö†Ô∏è  ‰∏ãÈôçÊåáÊ†á: {declines} ‰∏™")
    
    if improvements > declines:
        print("\n   üéâ ÊÄª‰ΩìËØÑ‰ª∑: ÊîπËøõÊàêÂäüÔºÅ")
    elif improvements == declines:
        print("\n   ‚ö° ÊÄª‰ΩìËØÑ‰ª∑: ÊåÅÂπ≥")
    else:
        print("\n   ‚ö†Ô∏è  ÊÄª‰ΩìËØÑ‰ª∑: ÈúÄË¶ÅËøõ‰∏ÄÊ≠•‰ºòÂåñ")
    
    print("\n" + "="*80)


def compare_metric(name, old_val, new_val, unit, higher_is_better=True):
    """ÂØπÊØîÂçï‰∏™ÊåáÊ†á"""
    if old_val is None or new_val is None:
        print(f"   ‚Ä¢ {name:20s}: Êï∞ÊçÆÁº∫Â§±")
        return
    
    diff = new_val - old_val
    diff_pct = (diff / old_val * 100) if old_val != 0 else 0
    
    # Âà§Êñ≠ÊòØÊîπËøõËøòÊòØÈÄÄÊ≠•
    if higher_is_better:
        is_improvement = diff > 0
    else:
        is_improvement = diff < 0
    
    arrow = "‚¨ÜÔ∏è" if diff > 0 else "‚¨áÔ∏è" if diff < 0 else "‚û°Ô∏è"
    status = "‚úÖ" if is_improvement else "‚ö†Ô∏è" if diff != 0 else "‚û°Ô∏è"
    
    if unit == '%':
        print(f"   {status} {name:20s}: {old_val:.2f}% ‚Üí {new_val:.2f}%  ({diff:+.2f}% {arrow}, {diff_pct:+.2f}%ÂèòÂåñ)")
    else:
        print(f"   {status} {name:20s}: {old_val:.4f} ‚Üí {new_val:.4f}  ({diff:+.4f} {arrow}, {diff_pct:+.2f}%ÂèòÂåñ)")


def main():
    """‰∏ªÂáΩÊï∞"""
    # Ëé∑ÂèñÈ°πÁõÆÊ†πÁõÆÂΩï
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = current_dir
    while os.path.basename(project_root) != 'yl_data_process':
        parent = os.path.dirname(project_root)
        if parent == project_root:
            break
        project_root = parent
    
    results_dir = os.path.join(project_root, 'backend/Agent4Edu/SelfDataProcess/results')
    
    # ÊóßÁâàÊä•ÂëäÔºàÊîπËøõÂâçÔºâ
    old_report = os.path.join(results_dir, 'three_mode_comparison_report.txt')
    
    # Êñ∞ÁâàÊä•ÂëäÔºàÊîπËøõÂêéÔºâ
    new_report = old_report  # ÊîπËøõÂêé‰ºöË¶ÜÁõñÂêå‰∏Ä‰∏™Êñá‰ª∂
    
    print("\n" + "="*80)
    print("üìÇ ËØªÂèñÂÆûÈ™åÊä•Âëä".center(80))
    print("="*80)
    print(f"\n   ÊóßÁâàÊä•Âëä: {old_report}")
    
    # Áî±‰∫éÊñ∞Áâà‰ºöË¶ÜÁõñÊóßÁâàÔºåÊàë‰ª¨ÈúÄË¶ÅÂú®ËøêË°åÊñ∞ÂÆûÈ™åÂâçÂ§á‰ªΩÊóßÊä•Âëä
    old_backup = os.path.join(results_dir, 'three_mode_comparison_report_OLD.txt')
    
    if not os.path.exists(old_backup):
        print(f"\n   ‚ö†Ô∏è  Êú™ÊâæÂà∞ÊóßÁâàÂ§á‰ªΩ")
        print(f"   üí° Âª∫ËÆÆÔºöÂú®ËøêË°åÊñ∞ÂÆûÈ™åÂâçÔºåÂÖàÂ§á‰ªΩÂΩìÂâçÊä•Âëä:")
        print(f"      cp {old_report} {old_backup}")
        return 1
    
    print(f"   Êñ∞ÁâàÊä•Âëä: {new_report}")
    print(f"   ÊóßÁâàÂ§á‰ªΩ: {old_backup}")
    
    # ÊèêÂèñÊåáÊ†á
    print("\nüìä ÊèêÂèñÊåáÊ†á...")
    old_metrics = extract_metrics_from_report(old_backup)
    new_metrics = extract_metrics_from_report(new_report)
    
    if old_metrics:
        print(f"   ‚úÖ ÊóßÁâàÊåáÊ†áÊèêÂèñÊàêÂäü ({len(old_metrics)} ‰∏™)")
    if new_metrics:
        print(f"   ‚úÖ Êñ∞ÁâàÊåáÊ†áÊèêÂèñÊàêÂäü ({len(new_metrics)} ‰∏™)")
    
    # ÂØπÊØîÁªìÊûú
    compare_results(old_metrics, new_metrics)
    
    return 0


if __name__ == '__main__':
    import sys
    sys.exit(main())


