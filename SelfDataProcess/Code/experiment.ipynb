{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ed720",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/jiangchangcheng/WorkSpace/yl_data_process/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "# --- 设置项目路径 ---\n",
    "# 为了能顺利导入 backend 中的自定义模块 (例如 doubao llm client)\n",
    "# 需要将项目根目录的 backend 文件夹加入到系统路径中\n",
    "def setup_project_path():\n",
    "    \"\"\"\n",
    "    动态查找项目根目录 yl_data_process 并将 backend 添加到 sys.path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 在 .ipynb 环境中，__file__ 未定义，使用 os.getcwd()\n",
    "        current_path = os.getcwd()\n",
    "    except NameError:\n",
    "        current_path = os.getcwd()\n",
    "\n",
    "    project_root = current_path\n",
    "    # 向上查找，直到找到 'yl_data_process'\n",
    "    while os.path.basename(project_root) != 'yl_data_process':\n",
    "        parent_path = os.path.dirname(project_root)\n",
    "        if parent_path == project_root: # 到达文件系统根目录\n",
    "            print(\"错误：无法找到项目根目录 'yl_data_process'。\")\n",
    "            print(\"请确保你的 notebook 文件位于 'yl_data_process' 项目文件夹内。\")\n",
    "            return None, None\n",
    "        project_root = parent_path\n",
    "\n",
    "    backend_path = os.path.join(project_root, 'backend')\n",
    "    if backend_path not in sys.path:\n",
    "        sys.path.append(backend_path)\n",
    "        print(f\"成功将 '{backend_path}' 添加到系统路径。\")\n",
    "    else:\n",
    "        print(f\"'{backend_path}' 已在系统路径中。\")\n",
    "\n",
    "    return project_root, backend_path\n",
    "\n",
    "PROJECT_ROOT, BACKEND_PATH = setup_project_path()\n",
    "\n",
    "# --- 导入自定义模块 ---\n",
    "if BACKEND_PATH:\n",
    "    try:\n",
    "        from llms.doubao import DouBaoLLM\n",
    "        print(\"成功导入 DouBaoLLM。\")\n",
    "        # 在这里初始化 LLM client\n",
    "        # 请确保你的环境变量或配置文件中包含了豆包的 API Key\n",
    "        # 例如: os.environ['DOUBAO_API_KEY'] = \"YOUR_KEY\"\n",
    "        llm_client = DouBaoLLM()\n",
    "    except ImportError as e:\n",
    "        print(f\"导入 DouBaoLLM 失败: {e}\")\n",
    "        print(\"请检查 backend/llms/doubao.py 文件是否存在且无误。\")\n",
    "        llm_client = None\n",
    "    except Exception as e:\n",
    "        print(f\"初始化 DouBaoLLM 时出错: {e}\")\n",
    "        print(\"请检查 API Key 是否已正确配置。\")\n",
    "        llm_client = None\n",
    "else:\n",
    "    llm_client = None\n",
    "    print(\"因未能设置项目路径，无法导入自定义模块。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0144581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 数据加载 ---\n",
    "# 根据 data_analysis.ipynb 中的代码进行数据加载\n",
    "# 确保 notebook 和 data 文件夹的相对路径正确\n",
    "print(\"=\"*20, \"2. 数据加载\", \"=\"*20)\n",
    "\n",
    "# 假设 experiment.ipynb 位于 SelfDataProcess/Code/\n",
    "# 那么数据文件夹路径就是 ../data/\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, 'backend/Agent4Edu/SelfDataProcess/data/')\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"错误: 数据路径不存在 -> {DATA_PATH}\")\n",
    "    print(\"请确认 'PROJECT_ROOT' 是否设置正确，以及数据文件是否已解压到指定位置。\")\n",
    "else:\n",
    "    print(f\"从以下路径加载数据: {DATA_PATH}\")\n",
    "    try:\n",
    "        # 加载所有CSV文件\n",
    "        questions_df = pd.read_csv(os.path.join(DATA_PATH, \"Questions.csv\"))\n",
    "        question_choices_df = pd.read_csv(os.path.join(DATA_PATH, \"Question_Choices.csv\"))\n",
    "        kcs_df = pd.read_csv(os.path.join(DATA_PATH, \"KCs.csv\"))\n",
    "        kc_relationships_df = pd.read_csv(os.path.join(DATA_PATH, \"KC_Relationships.csv\"))\n",
    "        question_kc_relationships_df = pd.read_csv(os.path.join(DATA_PATH, \"Question_KC_Relationships.csv\"))\n",
    "        transactions_df = pd.read_csv(os.path.join(DATA_PATH, \"Transaction.csv\"))\n",
    "\n",
    "        print(\"所有数据文件加载成功！\")\n",
    "        print(f\" - Questions: {questions_df.shape}\")\n",
    "        print(f\" - Question_Choices: {question_choices_df.shape}\")\n",
    "        print(f\" - KCs: {kcs_df.shape}\")\n",
    "        print(f\" - KC_Relationships: {kc_relationships_df.shape}\")\n",
    "        print(f\" - Question_KC_Relationships: {question_kc_relationships_df.shape}\")\n",
    "        print(f\" - Transaction: {transactions_df.shape}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"加载文件时出错: {e}\")\n",
    "        print(\"请检查 data 文件夹中是否包含所有必需的 .csv 文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 数据预处理 ---\n",
    "# 将分散在不同表中的数据进行合并，构建一个包含所有实验所需信息的 \"学生练习日志\" DataFrame\n",
    "print(\"=\"*20, \"3. 数据预处理\", \"=\"*20)\n",
    "\n",
    "# 步骤 1: 合并练习记录和问题内容\n",
    "# transactions_df (学生练习行为) + questions_df (问题详情)\n",
    "print(\"步骤 1/3: 合并练习记录和问题内容...\")\n",
    "merged_df = pd.merge(\n",
    "    transactions_df,\n",
    "    questions_df[['id', 'question_text', 'difficulty']],\n",
    "    left_on='question_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "# 重命名和清理\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'question_text': 'exer_content',\n",
    "    'answer_state': 'score',\n",
    "    'id_x': 'log_id' # 原始 transaction id\n",
    "}).drop(columns=['id_y'])\n",
    "\n",
    "print(f\"合并后 Shape: {merged_df.shape}\")\n",
    "\n",
    "\n",
    "# 步骤 2: 合并知识点信息\n",
    "# 为每个问题关联一个主要的知识点名称 (know_name)\n",
    "# 注意：一个问题可能关联多个知识点，这里我们简化处理，只取第一个关联的知识点\n",
    "print(\"\\n步骤 2/3: 合并知识点信息...\")\n",
    "\n",
    "# 首先获取 问题 -> 知识点ID 的映射\n",
    "# .drop_duplicates() 确保每个问题只取一个知识点ID（取第一个）\n",
    "question_to_kc_map = question_kc_relationships_df.drop_duplicates(subset=['question_id'])\n",
    "\n",
    "# 然后获取 知识点ID -> 知识点名称 的映射\n",
    "kc_id_to_name_map = kcs_df.set_index('id')['name']\n",
    "\n",
    "# 将知识点ID映射到问题-知识点关系表\n",
    "question_to_kc_map['know_name'] = question_to_kc_map['knowledgecomponent_id'].map(kc_id_to_name_map)\n",
    "question_to_kc_map = question_to_kc_map.rename(columns={'knowledgecomponent_id': 'know_code'})\n",
    "\n",
    "# 将知识点信息合并到主DataFrame\n",
    "student_logs_df = pd.merge(\n",
    "    merged_df,\n",
    "    question_to_kc_map[['question_id', 'know_code', 'know_name']],\n",
    "    on='question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# score 布尔值转为 0/1\n",
    "student_logs_df['score'] = student_logs_df['score'].astype(int)\n",
    "\n",
    "print(f\"合并后 Shape: {student_logs_df.shape}\")\n",
    "print(\"成功为每个练习记录关联了知识点。\")\n",
    "\n",
    "\n",
    "# 步骤 3: 按学生分组，构建最终的实验数据集\n",
    "# 最终数据结构是一个字典，key是学生ID，value是该学生所有练习记录的DataFrame\n",
    "print(\"\\n步骤 3/3: 按学生ID分组数据...\")\n",
    "all_student_records = {}\n",
    "for student_id, records in tqdm(student_logs_df.groupby('student_id')):\n",
    "    # 确保记录按时间排序\n",
    "    all_student_records[student_id] = records.sort_values(by='start_time').reset_index(drop=True)\n",
    "\n",
    "# 筛选掉练习记录过少的学生（例如少于10条），避免无法划分训练/测试集\n",
    "min_records_threshold = 10\n",
    "original_student_count = len(all_student_records)\n",
    "all_student_records = {\n",
    "    sid: recs for sid, recs in all_student_records.items()\n",
    "    if len(recs) >= min_records_threshold\n",
    "}\n",
    "filtered_student_count = len(all_student_records)\n",
    "\n",
    "print(f\"数据处理完成！\")\n",
    "print(f\"原始学生数: {original_student_count}\")\n",
    "print(f\"筛选后 (练习记录 >= {min_records_threshold}): {filtered_student_count} 名学生\")\n",
    "\n",
    "# 展示一个学生的样例数据\n",
    "sample_student_id = list(all_student_records.keys())[0]\n",
    "print(f\"\\n学生 {sample_student_id} 的练习记录 (前5条):\")\n",
    "display(all_student_records[sample_student_id].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 智能体 (Agent) 定义 ---\n",
    "# 在这里，我们根据 project_desc.md 中的描述，实现智能体的核心模块：\n",
    "# 1. Profile: 学生画像模块\n",
    "# 2. Memory: 记忆模块\n",
    "# 3. AgentAction: 行为模块\n",
    "print(\"=\"*20, \"4. Agent 核心模块定义\", \"=\"*20)\n",
    "\n",
    "\n",
    "# ------------------- 1. Agent 配置参数 -------------------\n",
    "# 从 project_desc.md 中提取的模拟参数\n",
    "SIM_PARAMS = {\n",
    "    'memory_source': 'real',\n",
    "    'learning_effect': 'yes',       # 是否启用学习效应 (记忆强化)\n",
    "    'forgetting_effect': 'yes',     # 是否启用遗忘效应\n",
    "    'reflection_choice': 'yes',     # 是否启用反思机制 (在本实验中简化，主要关注预测)\n",
    "    'sim_strategy': 'performance',\n",
    "    'gpt_type': 0,\n",
    "    'short_term_size': 5,          # 短期记忆容量\n",
    "    'long_term_thresh': 3,         # 长期记忆阈值 (强化次数)\n",
    "    'forget_lambda': 0.95          # 遗忘衰减系数阈值\n",
    "}\n",
    "\n",
    "\n",
    "# ------------------- 2. 学生画像 (Profile) 模块 -------------------\n",
    "class Profile:\n",
    "    \"\"\"\n",
    "    根据学生的历史练习记录，动态生成学生画像。\n",
    "    \"\"\"\n",
    "    def __init__(self, student_id, history_df):\n",
    "        self.student_id = student_id\n",
    "        if history_df.empty:\n",
    "            # 如果历史记录为空，则使用默认值\n",
    "            self.activity = \"medium\"\n",
    "            self.diversity = \"medium\"\n",
    "            self.preference = \"N/A\"\n",
    "            self.success_rate_val = 0.5\n",
    "            self.success_rate = \"medium\"\n",
    "            self.ability = \"common\"\n",
    "        else:\n",
    "            self._build_profile(history_df)\n",
    "\n",
    "    def _build_profile(self, df):\n",
    "        # 成功率\n",
    "        self.success_rate_val = df['score'].mean()\n",
    "        if self.success_rate_val > 0.6: self.success_rate = \"high\"\n",
    "        elif self.success_rate_val > 0.3: self.success_rate = \"medium\"\n",
    "        else: self.success_rate = \"low\"\n",
    "\n",
    "        # 能力\n",
    "        if self.success_rate_val > 0.5: self.ability = \"good\"\n",
    "        elif self.success_rate_val > 0.4: self.ability = \"common\"\n",
    "        else: self.ability = \"poor\"\n",
    "\n",
    "        # 活跃度 (简化为练习次数)\n",
    "        num_practices = len(df)\n",
    "        if num_practices > 200: self.activity = \"high\" # 阈值基于EDA观察\n",
    "        elif num_practices > 50: self.activity = \"medium\"\n",
    "        else: self.activity = \"low\"\n",
    "\n",
    "        # 多样性 (简化为接触的知识点广度)\n",
    "        kc_diversity = df['know_code'].nunique() / kcs_df['id'].nunique()\n",
    "        if kc_diversity > 0.75: self.diversity = \"high\"\n",
    "        elif kc_diversity > 0.4: self.diversity = \"medium\"\n",
    "        else: self.diversity = \"low\"\n",
    "\n",
    "        # 偏好\n",
    "        self.preference = df['know_name'].mode().iloc[0] if not df.empty else \"N/A\"\n",
    "\n",
    "    def build_prompt(self):\n",
    "        \"\"\"生成用于LLM的System Prompt\"\"\"\n",
    "        return (\n",
    "            f\"You are a student with {self.activity} activity, you maintain a {self.activity} level of online exercise activity and practice frequently.\\n\"\n",
    "            f\"You have {self.diversity} diversity, you explore diverse knowledge categories.\\n\"\n",
    "            f\"Most practiced concept: {self.preference}.\\n\"\n",
    "            f\"Success rate: {self.success_rate}.\\n\"\n",
    "            f\"Problem-solving ability: {self.ability}.\"\n",
    "        )\n",
    "\n",
    "# ------------------- 3. 记忆 (Memory) 模块 -------------------\n",
    "class Memory:\n",
    "    \"\"\"\n",
    "    实现三层记忆架构：事实记忆、短期记忆、长期记忆。\n",
    "    \"\"\"\n",
    "    def __init__(self, KCG, know_name_map):\n",
    "        self.factual = []  # 事实记忆: [content, concept_name, score, reinforcement_count, timestamp]\n",
    "        self.long = {\n",
    "            'significant_facts': [],\n",
    "            'learning_status': [],\n",
    "            'practiced_knowledge': set()\n",
    "        }\n",
    "        self.KCG = KCG\n",
    "        self.know_name_map = know_name_map\n",
    "        self.threshold = SIM_PARAMS['long_term_thresh']\n",
    "        self.short_size = SIM_PARAMS['short_term_size']\n",
    "        self.forget_lambda = SIM_PARAMS['forget_lambda']\n",
    "\n",
    "    def write_factual(self, record, time_step):\n",
    "        # record: (exer_content, know_name, score)\n",
    "        # 初始强化计次为1\n",
    "        self.factual.append([record[0], record[1], record[2], 1, time_step])\n",
    "        self.long['practiced_knowledge'].add(record[1])\n",
    "\n",
    "    def retrieve_short(self):\n",
    "        return self.factual[-self.short_size:]\n",
    "\n",
    "    def retrieve_long(self):\n",
    "        return {\n",
    "            'significant_facts': self.long['significant_facts'],\n",
    "            'learning_status': self.long['learning_status'],\n",
    "            'practiced_knowledge': list(self.long['practiced_knowledge'])\n",
    "        }\n",
    "\n",
    "    def reinforce(self, new_record, time_step):\n",
    "        # new_record: (exer_content, know_name, score)\n",
    "        # 1. 添加新事实\n",
    "        self.write_factual(new_record, time_step)\n",
    "        new_concept = new_record[1]\n",
    "\n",
    "        # 2. 遍历旧事实，计算相似度并强化\n",
    "        for fact in self.factual[:-1]: # 不包括刚刚添加的新事实\n",
    "            old_concept = fact[1]\n",
    "            # 基于KCG计算相似度 (简化：直接相连则相似)\n",
    "            if (new_concept, old_concept) in self.KCG or \\\n",
    "               (old_concept, new_concept) in self.KCG or \\\n",
    "               new_concept == old_concept:\n",
    "                fact[3] += 1 # 增加强化计次\n",
    "\n",
    "        # 3. 检查是否有事实可以迁移到长期记忆\n",
    "        existing_long_facts = {tuple(f[:3]) for f in self.long['significant_facts']}\n",
    "        for fact in self.factual:\n",
    "            if fact[3] >= self.threshold and tuple(fact[:3]) not in existing_long_facts:\n",
    "                self.long['significant_facts'].append(fact)\n",
    "                # print(f\"[Memory] Fact promoted to long-term: {fact[1]}\") # for debugging\n",
    "\n",
    "    def forget(self, current_time_step):\n",
    "        kept_facts = []\n",
    "        for fact in self.long['significant_facts']:\n",
    "            ts = fact[4] # 该记忆的时间戳\n",
    "            # 指数衰减函数 P = 1 / (1 + e^-(delta_t))\n",
    "            # delta_t 越大，P 越接近1 (越不容易忘)\n",
    "            # 我们用 1-P 作为遗忘概率，如果 1-P > lambda, 就遗忘\n",
    "            prob_keep = 1 / (1 + math.exp(-(current_time_step - ts)))\n",
    "            if prob_keep >= self.forget_lambda:\n",
    "                kept_facts.append(fact)\n",
    "            # else:\n",
    "                # print(f\"[Memory] Fact forgotten: {fact[1]}\") # for debugging\n",
    "        self.long['significant_facts'] = kept_facts\n",
    "\n",
    "\n",
    "# ------------------- 4. 行为 (Action) 模块 -------------------\n",
    "class AgentAction:\n",
    "    \"\"\"\n",
    "    执行四项核心任务，模拟学生的完整学习过程。\n",
    "    \"\"\"\n",
    "    def __init__(self, profile, memory, llm_client):\n",
    "        self.profile = profile\n",
    "        self.memory = memory\n",
    "        self.llm = llm_client\n",
    "\n",
    "    def _build_prompt(self, practice, short_mem, long_mem):\n",
    "        prompt = f\"Recommended Exercise:\\n\"\n",
    "        prompt += f\"- Textual Content: {practice['exer_content']}\\n\"\n",
    "        prompt += f\"- Knowledge Concept (true): {practice['know_name']}\\n\"\n",
    "\n",
    "        # Task 1\n",
    "        prompt += \"\\nTask 1: Based on your Profile and past experiences, decide if you want to attempt this exercise. If it seems too difficult or you are not confident, output 'No'; otherwise, output 'Yes'.\\n\"\n",
    "\n",
    "        # Short-term Memory\n",
    "        if short_mem:\n",
    "            prompt += \"\\nYour Short-term Memory (most recent exercises):\\n\"\n",
    "            for idx, r in enumerate(short_mem, 1):\n",
    "                correctness = 'Correct' if r[2] == 1 else 'Incorrect'\n",
    "                prompt += f\" Record {idx}: Content='{r[0][:50]}...', Concept='{r[1]}', Result={correctness}\\n\"\n",
    "\n",
    "        # Task 2\n",
    "        prompt += \"\\nTask 2: Identify the primary knowledge concept tested by this exercise from the list below. Output only the concept name.\\n\"\n",
    "        # 动态生成选项: 正确答案 + 2个已练习过的知识点\n",
    "        options = [practice['know_name']]\n",
    "        other_practiced = [k for k in long_mem.get('practiced_knowledge', []) if k != practice['know_name']]\n",
    "        options.extend(random.sample(other_practiced, min(2, len(other_practiced))))\n",
    "        random.shuffle(options)\n",
    "        for opt in options:\n",
    "            prompt += f\" - {opt}\\n\"\n",
    "\n",
    "        # Long-term Memory\n",
    "        if long_mem.get('significant_facts'):\n",
    "            prompt += \"\\nYour Long-term Memory (important facts you've reinforced):\\n\"\n",
    "            for idx, f in enumerate(long_mem['significant_facts'], 1):\n",
    "                 prompt += f\" Fact {idx}: You practiced on concept '{f[1]}' and your answer was {'Correct' if f[2]==1 else 'Incorrect'}. This is a significant memory.\\n\"\n",
    "\n",
    "        # Task 3 & 4\n",
    "        prompt += \"\\nTask 3: Propose a concise problem-solving idea and then give the final answer.\\n\"\n",
    "        prompt += \"Task 4: Predict whether you will answer this question correctly ('Yes' or 'No').\\n\"\n",
    "\n",
    "        # Output format\n",
    "        prompt += \"\\nOutput format must be exactly as follows:\\n\"\n",
    "        prompt += \"Task1: <Yes/No>\\nTask2: <concept_name>\\nTask3: <your idea and final answer>\\nTask4: <Yes/No>\"\n",
    "        return prompt\n",
    "\n",
    "    def _parse_response(self, resp_text):\n",
    "        ans = {}\n",
    "        lines = resp_text.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            try:\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    key = key.strip().lower()\n",
    "                    ans[key] = value.strip()\n",
    "            except:\n",
    "                continue # 忽略格式不正确的行\n",
    "        # 确保所有任务都有值，以防解析失败\n",
    "        for i in range(1, 5):\n",
    "            task_key = f'task{i}'\n",
    "            if task_key not in ans:\n",
    "                ans[task_key] = \"N/A\" # 默认值\n",
    "        return ans\n",
    "\n",
    "    async def simulate_step(self, practice, time_step):\n",
    "        # 1. 记忆检索\n",
    "        short_mem = self.memory.retrieve_short()\n",
    "        long_mem = self.memory.retrieve_long()\n",
    "\n",
    "        # 2. 构建提示\n",
    "        prompt = self._build_prompt(practice, short_mem, long_mem)\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': self.profile.build_prompt()},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ]\n",
    "\n",
    "        # 3. LLM 调用\n",
    "        raw_resp = \"\"\n",
    "        try:\n",
    "            raw_resp = await self.llm.chat(messages=messages, stream=False)\n",
    "        except Exception as e:\n",
    "            print(f\"LLM API call failed: {e}\")\n",
    "            raw_resp = \"Task1: N/A\\nTask2: N/A\\nTask3: N/A\\nTask4: N/A\" # 返回默认失败结果\n",
    "\n",
    "        ans = self._parse_response(raw_resp)\n",
    "\n",
    "        # 4. 记忆更新 (在外部循环中处理，因为需要先获得真实结果)\n",
    "        # 返回预测结果\n",
    "        return ans, raw_resp\n",
    "\n",
    "print(\"Agent 核心模块定义完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 实验设置与主循环 ---\n",
    "print(\"=\"*20, \"5. 实验设置与主循环\", \"=\"*20)\n",
    "\n",
    "# ------------------- 1. 实验参数 -------------------\n",
    "TEST_RATIO = 0.1\n",
    "# 为快速测试，可以只选择一部分学生\n",
    "# 设置为 None 则运行所有符合条件的学生\n",
    "NUM_STUDENTS_TO_RUN = 5 # e.g., 5, 10, or None for all\n",
    "RANDOM_STATE = 42 # for reproducibility\n",
    "\n",
    "# ------------------- 2. 构建 KCG (知识概念图) -------------------\n",
    "# KCG 用于记忆模块中的相似度计算\n",
    "# know_name_map 用于 id 和 name 之间的转换\n",
    "know_name_map = kcs_df.set_index('id')['name'].to_dict()\n",
    "know_id_map = {v: k for k, v in know_name_map.items()}\n",
    "\n",
    "# 将关系表中的 id 转换为 name\n",
    "kcg_df = kc_relationships_df.copy()\n",
    "kcg_df['from_kc_name'] = kcg_df['from_knowledgecomponent_id'].map(know_name_map)\n",
    "kcg_df['to_kc_name'] = kcg_df['to_knowledgecomponent_id'].map(know_name_map)\n",
    "\n",
    "# KCG 是一个包含了所有 (概念1, 概念2) 关联关系的集合\n",
    "KCG = set(zip(kcg_df['from_kc_name'], kcg_df['to_kc_name']))\n",
    "print(f\"KCG 构建完成，包含 {len(KCG)} 条知识点关联。\")\n",
    "\n",
    "\n",
    "# ------------------- 3. 实验主函数 -------------------\n",
    "async def run_experiment(student_ids):\n",
    "    \"\"\"\n",
    "    对指定学生列表运行完整的 Agent 模拟实验。\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for student_id in tqdm(student_ids, desc=\"Simulating Students\"):\n",
    "        student_records_df = all_student_records[student_id]\n",
    "\n",
    "        # 1. 数据集划分 (随机打乱)\n",
    "        train_df, test_df = train_test_split(\n",
    "            student_records_df,\n",
    "            test_size=TEST_RATIO,\n",
    "            random_state=RANDOM_STATE,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # 2. Agent 初始化\n",
    "        profile = Profile(student_id, train_df)\n",
    "        memory = Memory(KCG, know_name_map)\n",
    "        agent = AgentAction(profile, memory, llm_client)\n",
    "\n",
    "        # 3. 训练阶段 (填充 Agent 的记忆)\n",
    "        time_step = 0\n",
    "        for _, practice in train_df.iterrows():\n",
    "            time_step += 1\n",
    "            record = (practice['exer_content'], practice['know_name'], practice['score'])\n",
    "            \n",
    "            # 记忆强化\n",
    "            if SIM_PARAMS['learning_effect'] == 'yes':\n",
    "                memory.reinforce(record, time_step)\n",
    "            else:\n",
    "                 memory.write_factual(record, time_step)\n",
    "            \n",
    "            # 记忆遗忘\n",
    "            if SIM_PARAMS['forgetting_effect'] == 'yes':\n",
    "                memory.forget(time_step)\n",
    "\n",
    "        # 4. 测试阶段 (进行预测)\n",
    "        for _, practice in test_df.iterrows():\n",
    "            time_step += 1\n",
    "            \n",
    "            # Agent 进行预测\n",
    "            ans, raw_resp = await agent.simulate_step(practice, time_step)\n",
    "\n",
    "            # 记录结果\n",
    "            result = {\n",
    "                'student_id': student_id,\n",
    "                'question_id': practice['question_id'],\n",
    "                'true_know_name': practice['know_name'],\n",
    "                'true_score': practice['score'],\n",
    "                'predicted_task1_attempt': ans.get('task1', 'N/A'),\n",
    "                'predicted_task2_know_name': ans.get('task2', 'N/A'),\n",
    "                'predicted_task3_answer': ans.get('task3', 'N/A'),\n",
    "                'predicted_task4_score': ans.get('task4', 'N/A'),\n",
    "                'llm_raw_response': raw_resp\n",
    "            }\n",
    "            all_results.append(result)\n",
    "\n",
    "            # 测试后，同样需要将真实的练习记录更新到记忆中，以模拟连续学习过程\n",
    "            record = (practice['exer_content'], practice['know_name'], practice['score'])\n",
    "            if SIM_PARAMS['learning_effect'] == 'yes':\n",
    "                memory.reinforce(record, time_step)\n",
    "            else:\n",
    "                memory.write_factual(record, time_step)\n",
    "            if SIM_PARAMS['forgetting_effect'] == 'yes':\n",
    "                memory.forget(time_step)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# ------------------- 4. 运行实验 -------------------\n",
    "# 选取要运行的学生\n",
    "student_ids_to_run = list(all_student_records.keys())\n",
    "if NUM_STUDENTS_TO_RUN is not None:\n",
    "    # 随机抽样N个学生\n",
    "    random.seed(RANDOM_STATE)\n",
    "    student_ids_to_run = random.sample(student_ids_to_run, NUM_STUDENTS_TO_RUN)\n",
    "\n",
    "print(f\"\\n准备开始实验，将对 {len(student_ids_to_run)} 名学生进行模拟...\")\n",
    "\n",
    "# 运行异步主函数\n",
    "# 在Jupyter环境中，可以直接await\n",
    "# 如果是在普通脚本中，需要使用 asyncio.run()\n",
    "# results_df = await run_experiment(student_ids_to_run)\n",
    "# print(\"\\n实验完成！\")\n",
    "# display(results_df.head())\n",
    "\n",
    "# 注意：请在Jupyter环境中取消下面的注释并运行\n",
    "# 如果llm_client未成功初始化，运行会报错\n",
    "if llm_client:\n",
    "    print(\"LLM客户端已准备就绪，可以开始运行实验。\")\n",
    "    print(\"请取消下一行代码的注释以启动异步实验。\")\n",
    "    # asyncio.run(run_experiment(student_ids_to_run))\n",
    "else:\n",
    "    print(\"LLM客户端未初始化，无法运行实验。请检查之前的步骤。\")\n",
    "\n",
    "# # ----------------- 在Jupyter中运行的示例代码 -----------------\n",
    "# # 取消下面的注释来运行\n",
    "# async def main():\n",
    "#     global results_df\n",
    "#     if llm_client:\n",
    "#         print(\"开始运行实验...\")\n",
    "#         results_df = await run_experiment(student_ids_to_run)\n",
    "#         print(\"\\n实验完成！\")\n",
    "#         display(results_df)\n",
    "#     else:\n",
    "#         print(\"无法运行实验，LLM Client 未初始化。\")\n",
    "\n",
    "# # 在Jupyter Notebook中，可以直接运行 top-level await\n",
    "# # 如果不行，可以用下面的方式\n",
    "# # await main()\n",
    "# # 或者\n",
    "# # asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 结果评估 ---\n",
    "print(\"=\"*20, \"6. 结果评估\", \"=\"*20)\n",
    "\n",
    "# 假设 `results_df` 是 `run_experiment` 函数成功运行后返回的 DataFrame\n",
    "# 如果您还没有运行实验，可以创建一个假的 DataFrame 来测试评估逻辑\n",
    "try:\n",
    "    if 'results_df' not in globals() or results_df.empty:\n",
    "        print(\"未找到实验结果 'results_df'。创建一个示例 DataFrame 以进行演示。\")\n",
    "        # 创建一个示例性的假数据\n",
    "        data = {\n",
    "            'student_id': [1, 1, 2, 2],\n",
    "            'true_know_name': ['Data Model', 'Subset', 'Join', 'Data Model'],\n",
    "            'true_score': [1, 0, 1, 1],\n",
    "            'predicted_task1_attempt': ['Yes', 'yes', 'No', 'Yes.'],\n",
    "            'predicted_task2_know_name': ['Data Model', 'CREATE TABLE', 'Join', 'Data Model'],\n",
    "            'predicted_task4_score': ['Yes', 'No', 'no', ' Yes '],\n",
    "        }\n",
    "        results_df = pd.DataFrame(data)\n",
    "        print(\"示例数据已创建。\")\n",
    "except NameError:\n",
    "    # 捕获 NameError 以防 results_df 从未被定义\n",
    "    print(\"未找到实验结果 'results_df'。创建一个示例 DataFrame 以进行演示。\")\n",
    "    data = {\n",
    "        'student_id': [1, 1, 2, 2],\n",
    "        'true_know_name': ['Data Model', 'Subset', 'Join', 'Data Model'],\n",
    "        'true_score': [1, 0, 1, 1],\n",
    "        'predicted_task1_attempt': ['Yes', 'yes', 'No', 'Yes.'],\n",
    "        'predicted_task2_know_name': ['Data Model', 'CREATE TABLE', 'Join', 'Data Model'],\n",
    "        'predicted_task4_score': ['Yes', 'No', 'no', ' Yes '],\n",
    "    }\n",
    "    results_df = pd.DataFrame(data)\n",
    "    print(\"示例数据已创建。\")\n",
    "\n",
    "\n",
    "def evaluate_results(df):\n",
    "    \"\"\"\n",
    "    计算并展示各项评估指标。\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"结果DataFrame为空，无法进行评估。\")\n",
    "        return\n",
    "\n",
    "    print(\"--- 开始评估 ---\")\n",
    "    eval_df = df.copy()\n",
    "\n",
    "    # 1. 数据清洗和规范化\n",
    "    # 将 Yes/No 的预测结果统一转换为 1/0\n",
    "    def normalize_yes_no(value):\n",
    "        if isinstance(value, str):\n",
    "            val_lower = value.strip().lower()\n",
    "            if val_lower == 'yes':\n",
    "                return 1\n",
    "            if val_lower == 'no':\n",
    "                return 0\n",
    "        return np.nan # 返回 NaN 表示无法解析\n",
    "\n",
    "    eval_df['pred_t1'] = eval_df['predicted_task1_attempt'].apply(normalize_yes_no)\n",
    "    eval_df['pred_t4'] = eval_df['predicted_task4_score'].apply(normalize_yes_no)\n",
    "\n",
    "    # 2. 计算各项任务的准确率\n",
    "    \n",
    "    # Task 1: 决策是否尝试 (真实值总是1，因为学生实际做了)\n",
    "    # dropna() 用于处理无法解析的预测\n",
    "    acc_t1 = (eval_df['pred_t1'] == 1).mean()\n",
    "    \n",
    "    # Task 2: 知识概念识别\n",
    "    acc_t2 = (eval_df['predicted_task2_know_name'] == eval_df['true_know_name']).mean()\n",
    "\n",
    "    # Task 4: 答题正确率预测 (核心指标)\n",
    "    acc_t4 = (eval_df['pred_t4'] == eval_df['true_score']).mean()\n",
    "    \n",
    "    # 综合评估：我们将Task 4的准确率作为智能体对学生表现的总体预测准确度\n",
    "    agent_overall_accuracy = acc_t4\n",
    "\n",
    "    # 3. 打印结果报告\n",
    "    print(\"\\n--- 智能体表现评估报告 ---\")\n",
    "    print(f\"总测试样本数: {len(eval_df)}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"任务1 (尝试决策) 准确率: {acc_t1:.2%}\")\n",
    "    print(f\"任务2 (知识点识别) 准确率: {acc_t2:.2%}\")\n",
    "    print(f\"任务4 (表现预测) 准确率: {acc_t4:.2%}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"==> 智能体综合评估准确率 (基于Task 4): {agent_overall_accuracy:.2%} <==\")\n",
    "    \n",
    "    # 4. 显示带有评估结果的DataFrame\n",
    "    print(\"\\n--- 详细结果对比 (前10条) ---\")\n",
    "    display_cols = [\n",
    "        'student_id',\n",
    "        'true_know_name', 'predicted_task2_know_name',\n",
    "        'true_score', 'pred_t4'\n",
    "    ]\n",
    "    display(eval_df[display_cols].head(10))\n",
    "    \n",
    "    # 5. 混淆矩阵 (针对Task 4)\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # 移除无法解析的行\n",
    "        cm_df = eval_df[['true_score', 'pred_t4']].dropna()\n",
    "        \n",
    "        cm = confusion_matrix(cm_df['true_score'], cm_df['pred_t4'])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['预测错误', '预测正确'])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        disp.plot(ax=ax, cmap='Blues')\n",
    "        ax.set_title('任务4: 表现预测混淆矩阵')\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\n请安装 scikit-learn 和 matplotlib 以显示混淆矩阵: pip install scikit-learn matplotlib\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n无法生成混淆矩阵: {e}\")\n",
    "\n",
    "\n",
    "# 对实验结果运行评估函数\n",
    "evaluate_results(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b646195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
